{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92f334ff-3704-4383-b001-d0d81df50869",
   "metadata": {},
   "source": [
    "<center><h1>Nvidia's End-to-End Deep Learning for Self-Driving Cars</h1></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c9a7d6d-5cad-4af6-9aad-88675dde4677",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from cv2 import cv2\n",
    "from tqdm.auto import tqdm\n",
    "from math import pi\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchmetrics\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a9d1f0",
   "metadata": {},
   "source": [
    "## Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c322b423-a119-4c1e-be70-a2b29f43c3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    BATCH_SIZE = 3\n",
    "    EPOCHS = 1\n",
    "    IMG_HEIGHT = 66\n",
    "    IMG_WIDTH = 200\n",
    "    workers = 0\n",
    "    label_path = \"./driving_dataset/data.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c2050e-cd9b-4d0e-9f5c-d0b468612443",
   "metadata": {},
   "source": [
    "## Steering Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46a96600-af6e-4908-af3f-22c53c088fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SteerDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset to read images and corresponding steering angles.\n",
    "    \"\"\"\n",
    "    def __init__(self, paths, angles, transforms=None):\n",
    "        self.paths, self.angles = paths, angles\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = cv2.imread(self.paths[idx])\n",
    "        angle = self.angles[idx]\n",
    "        \n",
    "        # Apply transforms\n",
    "        if self.transforms is not None:\n",
    "            transformed_image = self.transforms(image=image)\n",
    "            image = transformed_image['image']\n",
    "            \n",
    "        # Convert image to torch.tensor\n",
    "        image_transform = ToTensorV2()(image=image)\n",
    "        image = image_transform['image']\n",
    "        \n",
    "        # Convert angle into a torch.tensor\n",
    "        angle = torch.tensor(angle, dtype=torch.float32)\n",
    "        \n",
    "        return {\n",
    "            \"image\": image,\n",
    "            \"angle\": angle\n",
    "        }\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a73d2b-992c-49dd-8c0c-7992acbe1aff",
   "metadata": {},
   "source": [
    "## Datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22246196-6cd2-4e0c-81ca-8dcdb4f9083c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SteerDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, label_path):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.label_path = label_path\n",
    "        \n",
    "        self.train_paths = []\n",
    "        self.train_angles = []\n",
    "        \n",
    "        self.test_paths = []\n",
    "        self.test_angles = []\n",
    "        \n",
    "        # Train & Test transforms\n",
    "        self.tfms = {\n",
    "            \"train\": A.Compose(\n",
    "                [\n",
    "                    A.Resize(\n",
    "                        width=Config.IMG_WIDTH, \n",
    "                        height=Config.IMG_HEIGHT\n",
    "                    ),\n",
    "                    A.HorizontalFlip(p=0.5),\n",
    "                ]\n",
    "            ),\n",
    "            \"test\": A.Resize(\n",
    "                width=Config.IMG_WIDTH, \n",
    "                height=Config.IMG_HEIGHT\n",
    "            )\n",
    "        }\n",
    "        \n",
    "    def prepare_data(self):\n",
    "        paths, angles = [], []\n",
    "        \n",
    "        with open(self.label_path, \"r\") as f:\n",
    "            for line in f.readlines():\n",
    "                image, angle = line.split(\" \")\n",
    "                full_path = f\"./driving_dataset/{image}\"\n",
    "                paths.append(full_path)\n",
    "                \n",
    "                # Convert from degree to radians to have smaller nuumbers\n",
    "                angles.append(float(angle) * pi/180) \n",
    "        \n",
    "        total_len = len(paths)\n",
    "        split = int(0.8 * total_len)\n",
    "        \n",
    "        self.train_paths = paths[:split]\n",
    "        self.train_angles = angles[:split]\n",
    "        \n",
    "        self.test_paths = paths[split:]\n",
    "        self.test_angles = angles[split:]\n",
    "                    \n",
    "    def setup(self, stage) -> None:\n",
    "        if stage in (\"fit\", None):\n",
    "            \n",
    "            # Splitting train dataset into train and validation datasets\n",
    "            ds = SteerDataset(\n",
    "                paths=self.train_paths, \n",
    "                angles=self.train_angles, \n",
    "                transforms=self.tfms['train']\n",
    "            )\n",
    "            split = int(len(ds) * 0.8)\n",
    "            train_idxs = list(range(0, split))\n",
    "            val_idxs = list(range(split, len(ds)))    \n",
    "            self.train_data = Subset(dataset=ds, indices=train_idxs)\n",
    "            self.val_data = Subset(dataset=ds, indices=val_idxs)\n",
    "            \n",
    "        if stage in (\"test\", None):\n",
    "            self.test_data = SteerDataset(\n",
    "                paths=self.test_paths, \n",
    "                angles=self.test_angles, \n",
    "                transforms=self.tfms['test'] \n",
    "            )\n",
    "            \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_data, batch_size=Config.BATCH_SIZE, num_workers=Config.workers)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_data, batch_size=Config.BATCH_SIZE, num_workers=Config.workers)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_data, batch_size=Config.BATCH_SIZE, num_workers=Config.workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c7d385",
   "metadata": {},
   "source": [
    "## Basic EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df50ff10",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm_ = SteerDataModule(label_path=Config.label_path)\n",
    "dm_.prepare_data()\n",
    "dm_.setup(\"fit\")\n",
    "dm_.setup(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "804c6215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(dm_.train_angles, density=True, bins=50, color='green', histtype='step')\n",
    "plt.hist(dm_.test_angles, density=True, bins=50, color='red', histtype='step')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed54ddc-2a49-4f39-a557-28693045f45a",
   "metadata": {},
   "source": [
    "*Obvservation*\n",
    "- The train and test steering angles do not overlap but they almost follow the same distribution\n",
    "- Most of the values fall between -2 to 2 radians\n",
    "- Maximum values are 0 radians"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4317d7",
   "metadata": {},
   "source": [
    "## Baseline model: mean model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "615c9765",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_angles = np.array(dm_.train_angles)\n",
    "test_angles = np.array(dm_.test_angles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2edc638e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST MSE (mean model): 0.19112687369474946\n",
      "TEST MSE (zero model): 0.19089104348993743\n"
     ]
    }
   ],
   "source": [
    "print(f\"TEST MSE (mean model): {np.mean(np.square(test_angles - train_angles.mean()))}\")\n",
    "print(f\"TEST MSE (zero model): {np.mean(np.square(test_angles - 0))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a0dc73",
   "metadata": {},
   "source": [
    "The mean model being our baseline, has a MSE of 0.1911.\n",
    "Any model we build should have a MSE of less than this to be of any use to us"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb400e0",
   "metadata": {},
   "source": [
    "## Autopilot model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e05d0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinMaxNormalization(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MinMaxNormalization, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        xmin = x.min()\n",
    "        xmax = x.max()\n",
    "        return (x - xmin)/(xmax - xmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "628558cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autopilot(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autopilot, self).__init__()\n",
    "        \n",
    "        self.normalization = MinMaxNormalization()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=3, \n",
    "            out_channels=24, \n",
    "            kernel_size=5,\n",
    "            stride=2\n",
    "        )\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=24, \n",
    "            out_channels=36, \n",
    "            kernel_size=5,\n",
    "            stride=2\n",
    "        )\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            in_channels=36, \n",
    "            out_channels=48, \n",
    "            kernel_size=5,\n",
    "            stride=2\n",
    "        )\n",
    "        self.conv4 = nn.Conv2d(\n",
    "            in_channels=48, \n",
    "            out_channels=64, \n",
    "            kernel_size=3\n",
    "        )\n",
    "        self.conv5 = nn.Conv2d(\n",
    "            in_channels=64, \n",
    "            out_channels=64, \n",
    "            kernel_size=3\n",
    "        )\n",
    "        self.fc1 = nn.Linear(\n",
    "            in_features=1152,\n",
    "            out_features=1164\n",
    "        )\n",
    "        self.fc2= nn.Linear(\n",
    "            in_features=1164,\n",
    "            out_features=100\n",
    "        )\n",
    "        self.fc3= nn.Linear(\n",
    "            in_features=100,\n",
    "            out_features=50\n",
    "        )\n",
    "        self.fc4= nn.Linear(\n",
    "            in_features=50,\n",
    "            out_features=10\n",
    "        )\n",
    "        self.fc5= nn.Linear(\n",
    "            in_features=10,\n",
    "            out_features=1\n",
    "        )\n",
    "        \n",
    "        # Initialize weights\n",
    "        self.apply(self._init_weights)\n",
    "        \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Conv2d):\n",
    "            nn.init.kaiming_normal_(module.weight)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Min-Max normalization\n",
    "        x = self.normalization(x)\n",
    "        \n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.relu(self.conv5(x))\n",
    "        \n",
    "        x = torch.flatten(x, 1)\n",
    "        \n",
    "        x = F.dropout(F.relu(self.fc1(x)))\n",
    "        x = F.dropout(F.relu(self.fc2(x)))\n",
    "        x = F.dropout(F.relu(self.fc3(x)))\n",
    "        x = F.dropout(F.relu(self.fc4(x)))\n",
    "        x = self.fc5(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c72769",
   "metadata": {},
   "source": [
    "## Lightning Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7a73aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SteerLitModel(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super(SteerLitModel, self).__init__()\n",
    "        self.model = Autopilot()\n",
    "        self.loss = nn.MSELoss()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.model.parameters(), lr=1e-4)\n",
    "\n",
    "    def forward(self, images):\n",
    "        return self.model(images)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images = batch[\"image\"]\n",
    "        labels = batch[\"angle\"]\n",
    "                \n",
    "        preds = self.forward(images)\n",
    "        loss = self.loss(input=preds[0], target=labels)\n",
    "\n",
    "        self.log(\"train_MSE\", loss, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images = batch[\"image\"]\n",
    "        labels = batch[\"angle\"]\n",
    "        \n",
    "        preds = self.forward(images)\n",
    "        loss = self.loss(input=preds[0], target=labels)\n",
    "\n",
    "        self.log(\"val_MSE\", loss, prog_bar=True)\n",
    "\n",
    "        return loss    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2beeb6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Running in fast_dev_run mode: will run a full train, val, test and prediction loop using 1 batch(es).\n",
      "`Trainer(limit_train_batches=1)` was configured so 1 batch per epoch will be used.\n",
      "`Trainer(limit_val_batches=1)` was configured so 1 batch will be used.\n",
      "`Trainer(limit_test_batches=1)` was configured so 1 batch will be used.\n",
      "`Trainer(limit_predict_batches=1)` was configured so 1 batch will be used.\n",
      "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type      | Params\n",
      "------------------------------------\n",
      "0 | model | Autopilot | 1.6 M \n",
      "1 | loss  | MSELoss   | 0     \n",
      "------------------------------------\n",
      "1.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.382     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5f4d01ac290496b8d91ae8644b847f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dm = SteerDataModule(label_path=Config.label_path)\n",
    "model = SteerLitModel()\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\"./models\", \n",
    "    monitor=\"val_acc\", \n",
    "    mode=\"max\", \n",
    "    verbose=True,\n",
    "    save_top_k=3,\n",
    "    filename='{epoch}-{val_loss:.2f}-{val_acc:.2f}'\n",
    ")\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor=\"val_acc\", \n",
    "    min_delta=0.00, \n",
    "    patience=3, \n",
    "    verbose=True, \n",
    "    mode=\"max\"\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    fast_dev_run=True,\n",
    "    logger=True,\n",
    "#     max_epochs=Config.EPOCHS,\n",
    "    accelerator=\"auto\", \n",
    "    callbacks=[checkpoint_callback, early_stop_callback],\n",
    ")\n",
    "\n",
    "trainer.fit(model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e92419",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "250.6px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
